{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001b5bd5",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81893f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import random\n",
    "import os\n",
    "print(\"XGBoost version:\", xgboost.__version__)\n",
    "print(xgboost.build_info())\n",
    "\n",
    "\n",
    "#global variables\n",
    "dir_path = \"C:\\\\school\\\\SchoolProgram\\\\NTUST_CSIE_DS\\\\DataSet\"\n",
    "outputPath = ''\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f0dc30",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259965a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv(os.path.join(dir_path, 'preprocessing_T1_basic.csv'))\n",
    "\n",
    "#auto drop non-numeric, nan columns\n",
    "df_preprocessing = df_origin.select_dtypes(include=[np.number]).dropna(axis=1)\n",
    "\n",
    "print(\"Processed data shape:\", df_preprocessing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f4887",
   "metadata": {},
   "source": [
    "正歸化、split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb664b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_preprocessing.copy().drop(columns=['label']))\n",
    "\n",
    "# 分割資料集\n",
    "y = df_preprocessing['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=random_state, stratify=y)\n",
    "\n",
    "# 使用 SMOTE 進行過採樣\n",
    "target_pos_ratio = 0.30  # 想要的正類比例\n",
    "sampling_strategy = target_pos_ratio / (1 - target_pos_ratio)\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=sampling_strategy, \n",
    "    random_state=random_state\n",
    ")\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(\"SMOTE 後訓練集大小:\", X_train.shape, \"正類比例:\", y_train.mean())\n",
    "print(f\"訓練集大小: {X_train.shape}\")\n",
    "print(f\"測試集大小: {X_test.shape}\")\n",
    "print(f\"訓練集中警示帳戶比例: {y_train.mean():.2%}\")\n",
    "print(f\"測試集中警示帳戶比例: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649cde9",
   "metadata": {},
   "source": [
    "training XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義參數網格\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 初始化 XGBoost 分類器\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=random_state,\n",
    "    tree_method='hist',\n",
    "    device='gpu'\n",
    ")\n",
    "\n",
    "print(\"開始訓練 XGBoost 模型...\")\n",
    "# 使用 GridSearchCV 搜索最佳參數\n",
    "grid_search = RandomizedSearchCV(estimator=xgb_clf, param_distributions=param_grid, cv=3, scoring='roc_auc', n_jobs=1, verbose=3, random_state=random_state)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 使用最佳參數初始化分類器\n",
    "best_params, best_socre = grid_search.best_params_, grid_search.best_score_\n",
    "xgb_clf = XGBClassifier(**best_params, random_state=random_state, tree_method='hist', device='gpu')\n",
    "print(f\"最佳參數:{best_params}, 最佳分數: {best_socre}\")\n",
    "\n",
    "# 初始化 XGBoost 分類器\n",
    "# xgb_clf = XGBClassifier(\n",
    "#     objective='binary:logistic',\n",
    "#     eval_metric='logloss',\n",
    "#     use_label_encoder=False,\n",
    "#     n_estimators=150,                 # 樹的數量\n",
    "#     max_depth=6,                      # 樹的最大深度\n",
    "#     learning_rate=0.1,                # 學習率\n",
    "#     subsample=0.8,                    # 訓練每棵樹時使用的樣本比例\n",
    "#     colsample_bytree=0.8,             # 訓練每棵樹時使用的特徵比例\n",
    "#     random_state=42,\n",
    "#     device='gpu',\n",
    "#     tree_method='hist'\n",
    "# )\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "xgb_clf.save_model('xgb_model.json')\n",
    "print(\"模型訓練完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4465d6",
   "metadata": {},
   "source": [
    "evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from Util import Evaluater\n",
    "\n",
    "# 評估模型\n",
    "Evaluater.evaluate_model(xgb_clf, (X_train, X_test, y_train, y_test))\n",
    "\n",
    "# 特徵重要性\n",
    "import matplotlib.pyplot as plt\n",
    "xgb_clf.feature_importances_\n",
    "xgb_clf.get_booster().get_score(importance_type='weight')\n",
    "xgboost.plot_importance(xgb_clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78f9c7",
   "metadata": {},
   "source": [
    "output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5792a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_test_acct = pd.read_csv(os.path.join(dir_path, 'acct_alert.csv'))\n",
    "df_test = df_origin[df_origin['acct'].isin(df_test_acct['acct'])].copy().select_dtypes(include=[np.number]).dropna(axis=1)\n",
    "X_test = scaler.transform(df_test.drop(columns=['label']))\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "df_pred = pd.DataFrame({\n",
    "    'acct': df_test_acct['acct'],\n",
    "    'label': y_test_pred\n",
    "})\n",
    "\n",
    "current_time = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "output_file = f\"xgboost_{current_time}.csv\"\n",
    "\n",
    "df_pred.to_csv(os.path.join(outputPath, output_file), index=False)\n",
    "print(f\"(Finish) Output saved to {os.path.join(outputPath, output_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntust_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
