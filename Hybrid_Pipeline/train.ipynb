{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb30c22",
   "metadata": {},
   "source": [
    "### Hybrid Pipeline 雙階段混和\n",
    "> 非監督篩式清洗 + 監督式分類\n",
    "\n",
    "> autoencoder(AE) + catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb6934",
   "metadata": {},
   "source": [
    "#### 載入外部程式庫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f26069",
   "metadata": {},
   "source": [
    "anaconda 需額外載入\n",
    "> tensorflow\n",
    "\n",
    "> catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48370ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal # panda 檢查\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model           #AE\n",
    "from tensorflow.keras.layers import Input, Dense    #AE\n",
    "from tensorflow.keras.optimizers import Adam        #AE\n",
    "from catboost import CatBoostClassifier             #catboost\n",
    "# Evaluater\n",
    "import sys\n",
    "import os\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eaf77a",
   "metadata": {},
   "source": [
    "#### 準備資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef192640",
   "metadata": {},
   "source": [
    "##### Load csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c90ec539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料：\n",
      "                                                acct  txn_count  first_txn_ts  \\\n",
      "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...          1       1953000   \n",
      "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...          1       4489500   \n",
      "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...          1       5823000   \n",
      "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...          1       1100100   \n",
      "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...          1        777300   \n",
      "\n",
      "   last_txn_ts  std_txn_ts  acct_type_x  cross_type    uni_amt  acct_type_y  \\\n",
      "0      1953000         0.0            2           1    47500.0            2   \n",
      "1      4489500         0.0            2           1     6150.0            2   \n",
      "2      5823000         0.0            2           1  1150000.0            2   \n",
      "3      1100100         0.0            2           1     8550.0            2   \n",
      "4       777300         0.0            2           1     1450.0            2   \n",
      "\n",
      "   num_unique_dest_accts  num_unique_source_accts  is_high_freq  \\\n",
      "0                    0.0                      1.0           0.0   \n",
      "1                    1.0                      0.0           0.0   \n",
      "2                    1.0                      0.0           0.0   \n",
      "3                    0.0                      1.0           0.0   \n",
      "4                    0.0                      1.0           0.0   \n",
      "\n",
      "   has_foreign_currency  label  \n",
      "0                     0      0  \n",
      "1                     0      0  \n",
      "2                     0      0  \n",
      "3                     0      0  \n",
      "4                     0      0  \n",
      "\n",
      "\n",
      "                                                acct  \\\n",
      "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...   \n",
      "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...   \n",
      "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...   \n",
      "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...   \n",
      "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...   \n",
      "\n",
      "   is_short_term_mass_receive  txn_count_ratio  txn_amt_ratio  is_night_txn  \\\n",
      "0                           0              0.0            0.0             0   \n",
      "1                           0              0.0            0.0             1   \n",
      "2                           0              0.0            0.0             0   \n",
      "3                           0              0.0            0.0             0   \n",
      "4                           0              0.0            0.0             1   \n",
      "\n",
      "   amt_diff  txn_count  first_txn_ts  last_txn_ts  std_txn_ts  acct_type_x  \\\n",
      "0    8100.0          1       1953000      1953000         0.0            2   \n",
      "1     410.0          1       4489500      4489500         0.0            2   \n",
      "2    1170.0          1       5823000      5823000         0.0            2   \n",
      "3    6100.0          1       1100100      1100100         0.0            2   \n",
      "4     150.0          1        777300       777300         0.0            2   \n",
      "\n",
      "   cross_type    uni_amt  acct_type_y  num_unique_dest_accts  \\\n",
      "0           1    47500.0            2                    0.0   \n",
      "1           1     6150.0            2                    1.0   \n",
      "2           1  1150000.0            2                    1.0   \n",
      "3           1     8550.0            2                    0.0   \n",
      "4           1     1450.0            2                    0.0   \n",
      "\n",
      "   num_unique_source_accts  is_high_freq  has_foreign_currency  label  \n",
      "0                      1.0           0.0                     0      0  \n",
      "1                      0.0           0.0                     0      0  \n",
      "2                      0.0           0.0                     0      0  \n",
      "3                      1.0           0.0                     0      0  \n",
      "4                      1.0           0.0                     0      0  \n",
      "\n",
      "\n",
      "                                                acct  \\\n",
      "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...   \n",
      "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...   \n",
      "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...   \n",
      "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...   \n",
      "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...   \n",
      "\n",
      "   is_short_term_mass_receive  txn_count_ratio  txn_amt_ratio  is_night_txn  \\\n",
      "0                           0              0.0            0.0             0   \n",
      "1                           0              0.0            0.0             1   \n",
      "2                           0              0.0            0.0             0   \n",
      "3                           0              0.0            0.0             0   \n",
      "4                           0              0.0            0.0             1   \n",
      "\n",
      "   amt_diff  txn_count  first_txn_ts  last_txn_ts  std_txn_ts  ...  \\\n",
      "0    8100.0          1       1953000      1953000         0.0  ...   \n",
      "1     410.0          1       4489500      4489500         0.0  ...   \n",
      "2    1170.0          1       5823000      5823000         0.0  ...   \n",
      "3    6100.0          1       1100100      1100100         0.0  ...   \n",
      "4     150.0          1        777300       777300         0.0  ...   \n",
      "\n",
      "   avg_recv_amt  var_recv_amt  std_recv_amt  total_send_amt  total_recv_amt  \\\n",
      "0        4050.0           0.0           0.0             0.0          4050.0   \n",
      "1           0.0           0.0           0.0           205.0             0.0   \n",
      "2           0.0           0.0           0.0           585.0             0.0   \n",
      "3        3050.0           0.0           0.0             0.0          3050.0   \n",
      "4          75.0           0.0           0.0             0.0            75.0   \n",
      "\n",
      "   usedChannelTypes  isFirstHighAmount_send  isFirstHighAmount_recv  \\\n",
      "0                 1                       0                       0   \n",
      "1                 1                       0                       0   \n",
      "2                 1                       0                       0   \n",
      "3                 1                       0                       0   \n",
      "4                 1                       0                       0   \n",
      "\n",
      "   repeatRatio  label  \n",
      "0          0.0      0  \n",
      "1          0.0      0  \n",
      "2          0.0      0  \n",
      "3          0.0      0  \n",
      "4          0.0      0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entities_path = {\n",
    "     \"T1\"   :   \"../DataSet/preprocessing_T1_basic.csv\"\n",
    "    ,\"T12\"  :   \"../DataSet/preprocessing_T1_2.csv\"\n",
    "    ,\"T123\" :   \"../DataSet/preprocessing_T1_2_3.csv\"\n",
    "}\n",
    "entities = {}\n",
    "\n",
    "# Load preprocessing and cut \n",
    "for index, path in entities_path.items():\n",
    "    entities[index] = pd.read_csv(path)\n",
    "\n",
    "print(\"原始資料：\")\n",
    "for v in entities.values():\n",
    "    print(f\"{v.head()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edad6c",
   "metadata": {},
   "source": [
    "##### Cut Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1658e",
   "metadata": {},
   "source": [
    "###### 切 acct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "125de259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料ID :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "acct",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "216b7245-1841-4337-b505-cdc2a98066a1",
       "rows": [
        [
         "0",
         "00000577cfcd0bde8ee693021419ef13a1f7f933ec862626d866616af32f2978"
        ],
        [
         "1",
         "00000eec52ea49377de91bc7b54eb3192943e6c20e0a51413dc1e733ee0dfad8"
        ],
        [
         "2",
         "000015150c92e2a41c4715a088df78d77a7d4f3017aadc3493d15a72fbeaf89c"
        ],
        [
         "3",
         "00002846e6b430580825e2b10fe3ff1e3ddb93f42c608daa8679723a694eb40d"
        ],
        [
         "4",
         "00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1fffa217980d912b6fde"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000015150c92e2a41c4715a088df78d77a7d4f3017aadc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                acct\n",
       "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...\n",
       "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...\n",
       "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...\n",
       "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...\n",
       "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cut preprocessing\n",
    "entities_id = pd.DataFrame()\n",
    "\n",
    "for index, entity in entities.items():\n",
    "    id = entity.iloc[:,[0]]\n",
    "    entities[index] = entity.iloc[:,1:]\n",
    "\n",
    "    # 判斷entity id 是否相同\n",
    "    if entities_id.empty:\n",
    "        entities_id = id\n",
    "    else :\n",
    "        try:\n",
    "            assert_frame_equal(entities_id, id)\n",
    "        except AssertionError as e:\n",
    "            print(f\"Data ID error : from {index}\")\n",
    "            print(e)\n",
    "\n",
    "print(\"資料ID :\")\n",
    "entities_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa50560",
   "metadata": {},
   "source": [
    "###### 切訓練資料用 ( label 分開 )  ( 工具 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cea3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入 pd 去掉 label \n",
    "# return pd label\n",
    "def cut_label(data):\n",
    "    temp = data.cpoy()\n",
    "    data.drop(columns=['label'])\n",
    "    return temp['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1bad82",
   "metadata": {},
   "source": [
    "###### 切資料集(定義)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b05b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x -> 無標籤資料集\n",
    "# y -> x 的標籤\n",
    "# test -> 結果產出用的 ; X_test -> 丟AE -> 拿\"高風險\"當結果的 X_test\n",
    "# X_train -> 丟進 AE -> 跑訓練\n",
    "# y_train -> 提取出 label 為 1 \n",
    "def tran_test_cut(df_preprocessing,rand_seed):\n",
    "    y = cut_label(df_preprocessing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_preprocessing, y, test_size=0.3, random_state=rand_seed, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65bf6d",
   "metadata": {},
   "source": [
    "#### 取得準確資料答案資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "506174e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_1_data(data,label):\n",
    "    label_1_data = pd.DataFrame()\n",
    "    for i in label:\n",
    "        if label[i] == 1:\n",
    "            label_1_data.add(data[i])\n",
    "    return label_1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in entities.values():\n",
    "    label = cut_label(entity)\n",
    "    print(get_label_1_data(entity,label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1b3cd",
   "metadata": {},
   "source": [
    "#### 資料前處理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec0b80",
   "metadata": {},
   "source": [
    "> Autoencoder 需要標準化\n",
    "\n",
    "> catboost 基本無須前處理\n",
    "\n",
    "> 警示上戶須加上特徵值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9b1b30",
   "metadata": {},
   "source": [
    "##### 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 標準化 MinMaxScaler ===\n",
    "def scaler(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    temp = scaler.fit_transform(data)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bef948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entities_scalr = {}\n",
    "for index,entity in entities.items():\n",
    "    entities_scalr[index] = scaler(entity)\n",
    "\n",
    "# print\n",
    "print(\"\\n標準化後：\")\n",
    "for v in entities_scalr.values():\n",
    "    print(v[:5]) # 顯示前 5 筆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1bf475",
   "metadata": {},
   "source": [
    "#### 建立 Autoencoder (AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_dim):\n",
    "    \"\"\"建立簡單的 AE 模型\"\"\"\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Encoder: 壓縮特徵\n",
    "    encoded = Dense(16, activation='relu')(input_layer)\n",
    "    encoded = Dense(8, activation='relu')(encoded)\n",
    "    \n",
    "    # Decoder: 還原特徵\n",
    "    decoded = Dense(16, activation='relu')(encoded)\n",
    "    output_layer = Dense(input_dim, activation='sigmoid')(decoded) # 若資料正規化到 0-1 用 sigmoid\n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531a9dc",
   "metadata": {},
   "source": [
    "#### 建立 Step1 : 非監督清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_unlabeled_scaled    標準化無標記綜合資料(含特徵)\n",
    "# X_unlabeled           無標記綜合資料(含特徵)\n",
    "def AE(X_unlabeled_scaled,X_unlabeled):\n",
    "    # 建立並訓練 AE\n",
    "    # 注意：這裡使用全部未標記資料訓練，模型會傾向學習\"大眾(正常)\"的模式\n",
    "    input_dim = X_unlabeled_scaled.shape[1]\n",
    "    ae_model = build_autoencoder(input_dim)\n",
    "    ae_model.fit(\n",
    "        X_unlabeled_scaled, X_unlabeled_scaled,\n",
    "        epochs=20, \n",
    "        batch_size=256, \n",
    "        shuffle=True, \n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # 計算重建誤差 (Reconstruction Error / MSE)\n",
    "    reconstructions = ae_model.predict(X_unlabeled_scaled)\n",
    "    mse = np.mean(np.power(X_unlabeled_scaled - reconstructions, 2), axis=1)\n",
    "\n",
    "    # 設定閾值：選取誤差最小的前 80% 作為「可靠的正常樣本 (Reliable Negatives)」\n",
    "    # 剩下的 20% 被視為模糊地帶，暫時不參與訓練，避免誤導模型\n",
    "    threshold = np.percentile(mse, 80) \n",
    "    mask_reliable = mse < threshold\n",
    "    \n",
    "\n",
    "    X_reliable_negatives = X_unlabeled[mask_reliable] # 取得原始數值(非 scaled)\n",
    "    X_uncertain = X_unlabeled[~mask_reliable] # 第一階段被剔除的高誤差群體\n",
    "    print(f\"篩選出 {len(X_reliable_negatives)} 筆可靠正常樣本，剔除 {len(X_unlabeled) - len(X_reliable_negatives)} 筆潛在雜訊。\")\n",
    "    return X_reliable_negatives,X_uncertain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d855f",
   "metadata": {},
   "source": [
    "#### 建立 Step2 : 監督式分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb090632",
   "metadata": {},
   "source": [
    "##### 定義模型及參數網格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 CatBoost 模型\n",
    "# auto_class_weights='Balanced' 對於異常偵測極為重要，自動處理樣本不平衡\n",
    "model = CatBoostClassifier(\n",
    "    auto_class_weights='Balanced', # 覆蓋預設值 (None -> Balanced)\n",
    "    eval_metric='AUC',             # 覆蓋預設值 (Logloss -> AUC)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bda0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義參數網格 (Parameter Grid)\n",
    "param_dist = {\n",
    "    'iterations': [200, 500],           # 樹的數量\n",
    "    'learning_rate': [0.01, 0.05, 0.1], # 學習率\n",
    "    'depth': [4, 6, 8],                 # 樹的深度 (太深容易 overfitting)\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],        # L2 正則化係數\n",
    "    'random_strength': [1, 5, 10],      # 防止過擬合的隨機性強度\n",
    "    'bagging_temperature': [0, 1]       # 貝葉斯自助抽樣的強度\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5d0b1",
   "metadata": {},
   "source": [
    "##### 資料集切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBoost_cut(X_reliable_negatives,X_known_anomalies):\n",
    "    # 建立&切分訓練集\n",
    "    # 建構訓練集：可靠正常 (Label 0) + 已知異常 (Label 1)\n",
    "    X_train_final = np.vstack([X_reliable_negatives, X_known_anomalies])\n",
    "    y_train_final = np.hstack([np.zeros(len(X_reliable_negatives)), np.ones(len(X_known_anomalies))])\n",
    "\n",
    "    # 切分驗證集 (為了調參使用)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_final, y_train_final, test_size=0.2, stratify=y_train_final, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b2ab2d",
   "metadata": {},
   "source": [
    "##### 參數調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBoost_get_best_model(train_turn,X_train, X_test, y_train, y_test):\n",
    "    # 使用 RandomizedSearchCV 進行參數調整\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter = train_turn,  # 隨機嘗試 10 組參數\n",
    "        scoring='roc_auc',\n",
    "       cv=3,       # 3-Fold Cross Validation\n",
    "       verbose=1,\n",
    "       n_jobs=-1   # 使用所有 CPU 核心\n",
    "    )\n",
    "\n",
    "    # 開始訓練與搜索\n",
    "    random_search.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "    # 取得最佳模型\n",
    "    best_model = random_search.best_estimator_\n",
    "    print(f\"\\n最佳參數組合: {random_search.best_params_}\")\n",
    "    print(f\"最佳 CV AUC 分數: {random_search.best_score_:.4f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673df47",
   "metadata": {},
   "source": [
    "#### 建立 Evaluater評分 (結果產出)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluater_score(model,X_train, X_test, y_train, y_test):\n",
    "    # 假設您的環境設定\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))\n",
    "    from Util import Evaluater\n",
    "\n",
    "    Evaluater.evaluate_model(model, (X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e057b",
   "metadata": {},
   "source": [
    "#### 實作 : 定義運行資料集(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89947237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entities 標籤 (dict)\n",
    "entities_index = []\n",
    "for index in entities:\n",
    "    entities_index.append(index)\n",
    "\n",
    "print(entities_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bf889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==== 實作引用資料參考上面 輸出 index ====#\n",
    "\n",
    "#       這裡手動調整跑訓練的資料集(參考上方輸出)\n",
    "#                       vv\n",
    "train_entities_index = [\"T1\"]\n",
    "#                       ^^\n",
    "#       這裡手動調整跑訓練的資料集(參考上方輸出)\n",
    "\n",
    "\n",
    "# 載入訓練用資料\n",
    "X_unlabeled_scaled = {} # 標準化無標記綜合資料(含特徵)\n",
    "X_unlabeled = {}        # 無標記綜合資料(含特徵)\n",
    "X_known_anomalies = {}  # 已知警示帳戶(含特徵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc109a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義輸出資料集\n",
    "best_models = {}\n",
    "entities_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b6835",
   "metadata": {},
   "source": [
    "#### 實作 : 資料分析 ( AE + CatBoost )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in train_entities_index:\n",
    "    seeds = [21,42,84]\n",
    "    # 根據 seed 切分資料\n",
    "    for seed in seeds:\n",
    "        # 切\n",
    "        train_data, test_data, train_label, test_label = tran_test_cut(entities[index],seed)\n",
    "        # AE\n",
    "        train_0, train_1 = AE(scaler(train_data),train_data)\n",
    "        test_0, test_1 = AE(scaler(test_data),test_data)\n",
    "        # 切分資料\n",
    "        X_train, X_test, y_train, y_test = catBoost_cut(train_0,get_label_1_data(train_data,train_label))\n",
    "        # CatBoost + 參數調整\n",
    "        turn = 10 # 10個參數\n",
    "        best_models[index] = catBoost_get_best_model(turn,X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # evaluater\n",
    "        get_evaluater_score(best_models[index],X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
