{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb30c22",
   "metadata": {},
   "source": [
    "### Hybrid Pipeline 雙階段混和\n",
    "> 非監督篩式清洗 + 監督式分類\n",
    "\n",
    "> autoencoder(AE) + catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb6934",
   "metadata": {},
   "source": [
    "#### 載入外部程式庫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f26069",
   "metadata": {},
   "source": [
    "anaconda 需額外載入\n",
    "> tensorflow\n",
    "\n",
    "> catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48370ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal # panda 檢查\n",
    "# model\n",
    "from src.data_processing import DataProcessor\n",
    "# Evaluater\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eaf77a",
   "metadata": {},
   "source": [
    "#### 準備資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef192640",
   "metadata": {},
   "source": [
    "##### Load csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90ec539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料：\n",
      "                                                acct  txn_count  first_txn_ts  \\\n",
      "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...          1       1953000   \n",
      "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...          1       4489500   \n",
      "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...          1       5823000   \n",
      "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...          1       1100100   \n",
      "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...          1        777300   \n",
      "\n",
      "   last_txn_ts  std_txn_ts  acct_type_x  cross_type    uni_amt  acct_type_y  \\\n",
      "0      1953000         0.0            2           1    47500.0            2   \n",
      "1      4489500         0.0            2           1     6150.0            2   \n",
      "2      5823000         0.0            2           1  1150000.0            2   \n",
      "3      1100100         0.0            2           1     8550.0            2   \n",
      "4       777300         0.0            2           1     1450.0            2   \n",
      "\n",
      "   num_unique_dest_accts  num_unique_source_accts  is_high_freq  \\\n",
      "0                    0.0                      1.0           0.0   \n",
      "1                    1.0                      0.0           0.0   \n",
      "2                    1.0                      0.0           0.0   \n",
      "3                    0.0                      1.0           0.0   \n",
      "4                    0.0                      1.0           0.0   \n",
      "\n",
      "   has_foreign_currency  label  \n",
      "0                     0      0  \n",
      "1                     0      0  \n",
      "2                     0      0  \n",
      "3                     0      0  \n",
      "4                     0      0  \n",
      "\n",
      "\n",
      "                                                acct  \\\n",
      "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...   \n",
      "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...   \n",
      "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...   \n",
      "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...   \n",
      "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...   \n",
      "\n",
      "   is_short_term_mass_receive  txn_count_ratio  txn_amt_ratio  is_night_txn  \\\n",
      "0                           0              0.0            0.0             0   \n",
      "1                           0              0.0            0.0             1   \n",
      "2                           0              0.0            0.0             0   \n",
      "3                           0              0.0            0.0             0   \n",
      "4                           0              0.0            0.0             1   \n",
      "\n",
      "   amt_diff  txn_count  first_txn_ts  last_txn_ts  std_txn_ts  acct_type_x  \\\n",
      "0    8100.0          1       1953000      1953000         0.0            2   \n",
      "1     410.0          1       4489500      4489500         0.0            2   \n",
      "2    1170.0          1       5823000      5823000         0.0            2   \n",
      "3    6100.0          1       1100100      1100100         0.0            2   \n",
      "4     150.0          1        777300       777300         0.0            2   \n",
      "\n",
      "   cross_type    uni_amt  acct_type_y  num_unique_dest_accts  \\\n",
      "0           1    47500.0            2                    0.0   \n",
      "1           1     6150.0            2                    1.0   \n",
      "2           1  1150000.0            2                    1.0   \n",
      "3           1     8550.0            2                    0.0   \n",
      "4           1     1450.0            2                    0.0   \n",
      "\n",
      "   num_unique_source_accts  is_high_freq  has_foreign_currency  label  \n",
      "0                      1.0           0.0                     0      0  \n",
      "1                      0.0           0.0                     0      0  \n",
      "2                      0.0           0.0                     0      0  \n",
      "3                      1.0           0.0                     0      0  \n",
      "4                      1.0           0.0                     0      0  \n",
      "\n",
      "\n",
      "                                                acct  \\\n",
      "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...   \n",
      "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...   \n",
      "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...   \n",
      "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...   \n",
      "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...   \n",
      "\n",
      "   is_short_term_mass_receive  txn_count_ratio  txn_amt_ratio  is_night_txn  \\\n",
      "0                           0              0.0            0.0             0   \n",
      "1                           0              0.0            0.0             1   \n",
      "2                           0              0.0            0.0             0   \n",
      "3                           0              0.0            0.0             0   \n",
      "4                           0              0.0            0.0             1   \n",
      "\n",
      "   amt_diff  txn_count  first_txn_ts  last_txn_ts  std_txn_ts  ...  \\\n",
      "0    8100.0          1       1953000      1953000         0.0  ...   \n",
      "1     410.0          1       4489500      4489500         0.0  ...   \n",
      "2    1170.0          1       5823000      5823000         0.0  ...   \n",
      "3    6100.0          1       1100100      1100100         0.0  ...   \n",
      "4     150.0          1        777300       777300         0.0  ...   \n",
      "\n",
      "   avg_recv_amt  var_recv_amt  std_recv_amt  total_send_amt  total_recv_amt  \\\n",
      "0        4050.0           0.0           0.0             0.0          4050.0   \n",
      "1           0.0           0.0           0.0           205.0             0.0   \n",
      "2           0.0           0.0           0.0           585.0             0.0   \n",
      "3        3050.0           0.0           0.0             0.0          3050.0   \n",
      "4          75.0           0.0           0.0             0.0            75.0   \n",
      "\n",
      "   usedChannelTypes  isFirstHighAmount_send  isFirstHighAmount_recv  \\\n",
      "0                 1                       0                       0   \n",
      "1                 1                       0                       0   \n",
      "2                 1                       0                       0   \n",
      "3                 1                       0                       0   \n",
      "4                 1                       0                       0   \n",
      "\n",
      "   repeatRatio  label  \n",
      "0          0.0      0  \n",
      "1          0.0      0  \n",
      "2          0.0      0  \n",
      "3          0.0      0  \n",
      "4          0.0      0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entities_path = {\n",
    "     \"T1\"   :   \"../DataSet/preprocessing_T1_basic.csv\"\n",
    "    ,\"T12\"  :   \"../DataSet/preprocessing_T1_2.csv\"\n",
    "    ,\"T123\" :   \"../DataSet/preprocessing_T1_2_3.csv\"\n",
    "}\n",
    "entities = {}\n",
    "\n",
    "# Load preprocessing and cut \n",
    "for index, path in entities_path.items():\n",
    "    entities[index] = pd.read_csv(path)\n",
    "\n",
    "print(\"原始資料：\")\n",
    "for v in entities.values():\n",
    "    print(f\"{v.head()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edad6c",
   "metadata": {},
   "source": [
    "##### Cut acct ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125de259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料ID :\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "acct",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e0e849a5-429f-4b5f-a010-7243aa569690",
       "rows": [
        [
         "0",
         "00000577cfcd0bde8ee693021419ef13a1f7f933ec862626d866616af32f2978"
        ],
        [
         "1",
         "00000eec52ea49377de91bc7b54eb3192943e6c20e0a51413dc1e733ee0dfad8"
        ],
        [
         "2",
         "000015150c92e2a41c4715a088df78d77a7d4f3017aadc3493d15a72fbeaf89c"
        ],
        [
         "3",
         "00002846e6b430580825e2b10fe3ff1e3ddb93f42c608daa8679723a694eb40d"
        ],
        [
         "4",
         "00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1fffa217980d912b6fde"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000015150c92e2a41c4715a088df78d77a7d4f3017aadc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                acct\n",
       "0  00000577cfcd0bde8ee693021419ef13a1f7f933ec8626...\n",
       "1  00000eec52ea49377de91bc7b54eb3192943e6c20e0a51...\n",
       "2  000015150c92e2a41c4715a088df78d77a7d4f3017aadc...\n",
       "3  00002846e6b430580825e2b10fe3ff1e3ddb93f42c608d...\n",
       "4  00002b3d8f9c7b91c407a5725849deb521fcf1dd5eea1f..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cut preprocessing\n",
    "entities_id = pd.DataFrame()\n",
    "\n",
    "for index, entity in entities.items():\n",
    "    id = entity.iloc[:,[0]]\n",
    "    entities[index] = entity.iloc[:,1:]\n",
    "\n",
    "    # 判斷entity id 是否相同\n",
    "    if entities_id.empty:\n",
    "        entities_id = id\n",
    "    else :\n",
    "        try:\n",
    "            assert_frame_equal(entities_id, id)\n",
    "        except AssertionError as e:\n",
    "            print(f\"Data ID error : from {index}\")\n",
    "            print(e)\n",
    "\n",
    "print(\"資料ID :\")\n",
    "entities_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673df47",
   "metadata": {},
   "source": [
    "#### 建立 Evaluater評分 (結果產出)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1d363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluater_score(model,X_train, X_test, y_train, y_test):\n",
    "    # 假設您的環境設定\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))\n",
    "    from Util import Evaluater\n",
    "\n",
    "    Evaluater.evaluate_model(model, (X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e057b",
   "metadata": {},
   "source": [
    "#### 實作 : 定義運行資料集(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89947237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T1', 'T12', 'T123']\n"
     ]
    }
   ],
   "source": [
    "# entities 標籤 (dict)\n",
    "entities_index = []\n",
    "for index in entities:\n",
    "    entities_index.append(index)\n",
    "\n",
    "print(entities_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35bf889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==== 實作引用資料參考上面 輸出 index ====#\n",
    "\n",
    "#       這裡手動調整跑訓練的資料集(參考上方輸出)\n",
    "#                       vv\n",
    "train_entities_index = [\"T1\",\"T12\",\"T123\"]\n",
    "#                       ^^\n",
    "#       這裡手動調整跑訓練的資料集(參考上方輸出)\n",
    "\n",
    "#       這裡手動調整跑訓練的次數\n",
    "#                  vv\n",
    "model_train_turn = 50\n",
    "#                  ^^\n",
    "#       這裡手動調整跑訓練的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc109a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義輸出資料集\n",
    "best_models = {}\n",
    "\n",
    "# 定義訓練/測試資料庫\n",
    "cutted_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b6835",
   "metadata": {},
   "source": [
    "#### 實作 : 資料分析 ( AE + CatBoost )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe86733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import AE_CatBoost_Model\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from Util.PrepareData import prepare_data_pure,prepare_data_cutting,prepare_data_smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = T1\n",
      "訓練集大小: (129451, 12), 測試集大小: (54275, 12)\n",
      "訓練集正類比例: 2.72%, 測試集正類比例: 0.55%\n",
      "測試資料 (X_test) 的特徵數量: 12\n",
      "index = T12\n",
      "訓練集大小: (129451, 17), 測試集大小: (54275, 17)\n",
      "訓練集正類比例: 2.72%, 測試集正類比例: 0.55%\n",
      "測試資料 (X_test) 的特徵數量: 17\n",
      "index = T123\n",
      "訓練集大小: (129451, 33), 測試集大小: (54275, 33)\n",
      "訓練集正類比例: 2.72%, 測試集正類比例: 0.55%\n",
      "測試資料 (X_test) 的特徵數量: 33\n"
     ]
    }
   ],
   "source": [
    "for index in train_entities_index:\n",
    "    # 切資料\n",
    "    print(f\"\\nindex = {index}\")\n",
    "    X_train, X_test, y_train, y_test =  prepare_data_cutting(entity)\n",
    "    cutted_data[index] = X_train, X_test, y_train, y_test\n",
    "    \n",
    "    # show label num\n",
    "    actual_cols = X_test.shape[1] if len(X_test.shape) > 1 else 1\n",
    "    print(f\"測試資料 (X_test) 的特徵數量: {actual_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b8385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index = T1\n",
      "測試資料 (X_test) 的特徵數量: 12\n",
      "測試資料 (X_train) 的特徵數量: 12\n",
      "==================================================\n",
      "步驟 1: 訓練 AutoEncoder 並篩選樣本...\n",
      "==================================================\n",
      "\u001b[1m4046/4046\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 515us/step\n",
      "篩選出 103560 筆可靠正常樣本，剔除 25891 筆潛在雜訊。\n",
      "\n",
      "==================================================\n",
      "步驟 2: 建立混合資料集並訓練 CatBoost...\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "CatBoost 訓練完成\n",
      "==================================================\n",
      "模型預期的特徵數量 (訓練時): 33\n",
      "\n",
      "index = T12\n",
      "測試資料 (X_test) 的特徵數量: 17\n",
      "測試資料 (X_train) 的特徵數量: 17\n",
      "==================================================\n",
      "步驟 1: 訓練 AutoEncoder 並篩選樣本...\n",
      "==================================================\n",
      "\u001b[1m4046/4046\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 574us/step\n",
      "篩選出 103560 筆可靠正常樣本，剔除 25891 筆潛在雜訊。\n",
      "\n",
      "==================================================\n",
      "步驟 2: 建立混合資料集並訓練 CatBoost...\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "CatBoost 訓練完成\n",
      "==================================================\n",
      "模型預期的特徵數量 (訓練時): 33\n",
      "\n",
      "index = T123\n",
      "測試資料 (X_test) 的特徵數量: 33\n",
      "測試資料 (X_train) 的特徵數量: 33\n",
      "==================================================\n",
      "步驟 1: 訓練 AutoEncoder 並篩選樣本...\n",
      "==================================================\n",
      "\u001b[1m4046/4046\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604us/step\n",
      "篩選出 103560 筆可靠正常樣本，剔除 25891 筆潛在雜訊。\n",
      "\n",
      "==================================================\n",
      "步驟 2: 建立混合資料集並訓練 CatBoost...\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "CatBoost 訓練完成\n",
      "==================================================\n",
      "模型預期的特徵數量 (訓練時): 33\n"
     ]
    }
   ],
   "source": [
    "for index in train_entities_index:\n",
    "    print(f\"\\nindex = {index}\")\n",
    "    # init model & 資料暫存庫\n",
    "    model = AE_CatBoost_Model()\n",
    "    best_models[index] = None\n",
    "    entity = entities[index]\n",
    "\n",
    "    # 切分訓練與測試資料(第一次切分 : 統一切分)\n",
    "    X_train, X_test, y_train, y_test =  cutted_data[index]\n",
    "\n",
    "    # 訓練模型\n",
    "    model.fit(X_train, y_train) \n",
    "    # model.fit(X_train, y_train, train_turn=20,tune_params=True)\n",
    "        \n",
    "    # 儲存最佳模型\n",
    "    best_models[index] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "040854c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = T1\n",
      "模型預期的特徵數量 (訓練時): 33\n",
      "測試資料 (X_test) 的特徵數量: 12\n",
      "\n",
      "[錯誤原因] 測試資料少給了 21 個欄位！\n",
      "請檢查：是否在訓練時有加入 'AE 重建誤差' 或其他特徵，但測試時忘記加了？\n",
      "\n",
      "--------------------------------------------------\n",
      "evaluater 測試：\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/libs/data/model_dataset_compatibility.cpp:72: Feature 12 is present in model but not in pool.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatBoostError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mevaluater 測試：\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mget_evaluater_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 找回 label = 1 的準確度\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m- entity_label1 : 全部為 label 1 的資料集\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m- X_label1, y_label1 : 從 entity_label1 切分出來的訓練資料 (All label 1)\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m- X_test_label1, y__test_label1 : 從 X_test 切分出來的測試資料 (All label 1)\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_evaluater_score\u001b[39m\u001b[34m(model, X_train, X_test, y_train, y_test)\u001b[39m\n\u001b[32m      3\u001b[39m sys.path.append(os.path.dirname(os.getcwd()))\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mUtil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Evaluater\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mEvaluater\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1than\\Documents\\Computer_Science_Team_Project\\DataScienceFinalProject\\NTUST_CSIE_DS\\Util\\Evaluater.py:24\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_data)\u001b[39m\n\u001b[32m     21\u001b[39m X_train, X_test, y_train, y_test = test_data\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 基本預測\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m y_train_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m y_test_pred = model.predict(X_test)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 若模型支援 predict_proba，則計算 ROC AUC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1than\\Documents\\Computer_Science_Team_Project\\DataScienceFinalProject\\NTUST_CSIE_DS\\Hybrid_Pipeline\\src\\model.py:105\u001b[39m, in \u001b[36mAE_CatBoost_Model.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m預測樣本的標籤\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33;03m- 預測標籤 (0: 正常, 1: 異常)\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m  \u001b[38;5;66;03m# 1. 先取得預測機率 (Shape: [n_samples, 2])\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# 注意：我們只需要 \"異常 (Class 1)\" 的機率\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m probs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcat_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# 2. 根據設定的閾值進行切分\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# 大於等於閾值回傳 1，否則回傳 0\u001b[39;00m\n\u001b[32m    109\u001b[39m predictions = (probs >= \u001b[38;5;28mself\u001b[39m.threshold).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1than\\anaconda3\\envs\\data\\Lib\\site-packages\\catboost\\core.py:5351\u001b[39m, in \u001b[36mCatBoostClassifier.predict_proba\u001b[39m\u001b[34m(self, X, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[39m\n\u001b[32m   5309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ntree_start=\u001b[32m0\u001b[39m, ntree_end=\u001b[32m0\u001b[39m, thread_count=-\u001b[32m1\u001b[39m, verbose=\u001b[38;5;28;01mNone\u001b[39;00m, task_type=\u001b[33m\"\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   5310\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5311\u001b[39m \u001b[33;03m    Predict class probability with X.\u001b[39;00m\n\u001b[32m   5312\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5349\u001b[39m \u001b[33;03m            with probability for every class for each object.\u001b[39;00m\n\u001b[32m   5350\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mProbability\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict_proba\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1than\\anaconda3\\envs\\data\\Lib\\site-packages\\catboost\\core.py:2623\u001b[39m, in \u001b[36mCatBoost._predict\u001b[39m\u001b[34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[39m\n\u001b[32m   2620\u001b[39m data, data_is_single_object = \u001b[38;5;28mself\u001b[39m._process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[32m   2621\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_prediction_type(prediction_type)\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m data_is_single_object \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1than\\anaconda3\\envs\\data\\Lib\\site-packages\\catboost\\core.py:1842\u001b[39m, in \u001b[36m_CatBoostBase._base_predict\u001b[39m\u001b[34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[39m\n\u001b[32m   1841\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_base_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type):\n\u001b[32m-> \u001b[39m\u001b[32m1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5155\u001b[39m, in \u001b[36m_catboost._CatBoost._base_predict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5162\u001b[39m, in \u001b[36m_catboost._CatBoost._base_predict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mCatBoostError\u001b[39m: catboost/libs/data/model_dataset_compatibility.cpp:72: Feature 12 is present in model but not in pool."
     ]
    }
   ],
   "source": [
    "for index in train_entities_index:\n",
    "    print(f\"index = {index}\")\n",
    "    # 重切資料\n",
    "    X_train, X_test, y_train, y_test =  cutted_data[index]\n",
    "    \n",
    "    # 1. 取得模型物件\n",
    "    current_model = best_models[index].cat_model\n",
    "\n",
    "    # 2. 檢查模型訓練時用了幾個特徵\n",
    "    # 優先嘗試 n_features_in_，如果沒有則嘗試計算 feature_names_\n",
    "    if hasattr(current_model, 'n_features_in_'):\n",
    "        expected_cols = current_model.n_features_in_\n",
    "    elif hasattr(current_model, 'feature_names_'):\n",
    "        expected_cols = len(current_model.feature_names_)\n",
    "    else:\n",
    "        expected_cols = \"未知 (無法讀取屬性)\"\n",
    "\n",
    "    print(f\"模型預期的特徵數量 (訓練時): {expected_cols}\")\n",
    "\n",
    "    # 3. 檢查現在傳入的資料有幾個特徵\n",
    "    actual_cols = X_test.shape[1] if len(X_test.shape) > 1 else 1\n",
    "    print(f\"測試資料 (X_test) 的特徵數量: {actual_cols}\")\n",
    "\n",
    "    # 4. 自動判斷\n",
    "    if isinstance(expected_cols, int):\n",
    "        if expected_cols != actual_cols:\n",
    "            diff = expected_cols - actual_cols\n",
    "            if diff > 0:\n",
    "                print(f\"\\n[錯誤原因] 測試資料少給了 {diff} 個欄位！\")\n",
    "                print(\"請檢查：是否在訓練時有加入 'AE 重建誤差' 或其他特徵，但測試時忘記加了？\")\n",
    "            else:\n",
    "                print(f\"\\n[錯誤原因] 測試資料多出了 {abs(diff)} 個欄位！\")\n",
    "                print(\"請檢查：測試資料是否忘記刪除 ID 欄位或 Label 欄位？\")\n",
    "        else:\n",
    "            print(\"\\n[狀態] 欄位數量一致。如果還是報錯，請確認是否為 DataFrame vs Array 的格式問題 (請使用 .values)。\")\n",
    "\n",
    "    # evaluater\n",
    "    print (\"\\n\"+\"-\"*50)\n",
    "    print (\"evaluater 測試：\")\n",
    "    print (\"-\"*50)\n",
    "    get_evaluater_score(best_models[index],X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    # 找回 label = 1 的準確度\n",
    "    \"\"\"\n",
    "    - entity_label1 : 全部為 label 1 的資料集\n",
    "    - X_label1, y_label1 : 從 entity_label1 切分出來的訓練資料 (All label 1)\n",
    "    - X_test_label1, y__test_label1 : 從 X_test 切分出來的測試資料 (All label 1)\n",
    "    \"\"\"\n",
    "    # All label 1\n",
    "    entity_label1 = entity.copy()\n",
    "    label,entity_label1_cut = DataProcessor.cut_label(entity_label1) # label -> enitiy的 label ; entity_label1_cut -> entity 移除 label 列 \n",
    "    X_label1 = DataProcessor.split_diff_label(entity_label1_cut, label, positive_label=True) # label1 -> entity 移除 label 列並取 label = 1 (alert)\n",
    "    y_label1 = pd.Series([1]*X_label1.shape[0]) # 全部為 1\n",
    "    # no train label 1\n",
    "    X_test_label1 = DataProcessor.split_diff_label(X_test, y_test, positive_label=True) # 從 X_test 切分出來的測試資料 (All label 1) \n",
    "    y_test_label1 = pd.Series([1]*X_test_label1.shape[0])\n",
    "\n",
    "    # 產生分數\n",
    "    print (\"\\n\"+\"-\"*50)\n",
    "    print (\"Label = 1 (alert) 的準確度：\")\n",
    "    print (\"-\"*50)\n",
    "    get_evaluater_score(best_models[index],X_train, X_label1, y_train, y_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd040e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "for index in train_entities_index:\n",
    "        \n",
    "    # 重切資料\n",
    "    X_train, X_test, y_train, y_test =  cutted_data[index]\n",
    "\n",
    "    # show label num\n",
    "    actual_cols = X_test.shape[1] if len(X_test.shape) > 1 else 1\n",
    "    print(f\"測試資料 (X_test) 的特徵數量: {actual_cols}\")\n",
    "\n",
    "    # 1. 取得預測機率\n",
    "    # 務必使用測試集 (Test Set)\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 2. 建立畫布\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "    # 3. 使用方法一畫出基礎曲線 (Blue Line)\n",
    "    display = PrecisionRecallDisplay.from_predictions(\n",
    "        y_test, \n",
    "        y_probs, \n",
    "        name=\"AE + CatBoost\",\n",
    "        plot_chance_level=True,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # =======================================================\n",
    "    # 新增功能：計算並標示「最佳 F1-Score」的點\n",
    "    # =======================================================\n",
    "\n",
    "    # 4. 手動計算 Precision, Recall 和 Thresholds 來找最佳解\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "    # 5. 計算每個點的 F1-Score\n",
    "    # F1 = 2 * (P * R) / (P + R)\n",
    "    # 加上 1e-8 是為了避免分母為 0 報錯\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    # 6. 找出 F1 最高點的索引 (Index)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "\n",
    "    best_p = precision[best_idx]\n",
    "    best_r = recall[best_idx]\n",
    "    best_f1 = f1_scores[best_idx]\n",
    "\n",
    "    # 注意：thresholds 陣列的長度比 precision/recall 少 1\n",
    "    # 如果 best_idx 是最後一個，代表閾值非常高\n",
    "    best_thresh = thresholds[best_idx] if best_idx < len(thresholds) else 1.0\n",
    "\n",
    "    # 7. 在原本的圖上疊加一個紅點\n",
    "    ax.scatter(best_r, best_p, s=150, c='red', edgecolors='black', zorder=10, \n",
    "            label=f'Best F1 (Th={best_thresh:.3f})')\n",
    "\n",
    "    # 8. 加上文字註解\n",
    "    text_label = f'Best F1={best_f1:.2f}\\nRecall={best_r:.2f}\\nPrecision={best_p:.2f}\\nThreshold={best_thresh:.3f}'\n",
    "\n",
    "    ax.annotate(text_label, \n",
    "            xy=(best_r, best_p), \n",
    "            xytext=(30, 40), # 文字稍微偏右上\n",
    "            textcoords='offset points',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.9),\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "    # =======================================================\n",
    "\n",
    "    ax.set_title(\"Precision-Recall Curve with Best F1 Point\")\n",
    "    ax.grid(linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend(loc=\"lower left\") # 圖例放左下角避免擋住線\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
