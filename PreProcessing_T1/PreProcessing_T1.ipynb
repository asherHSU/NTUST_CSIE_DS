{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## T1 Feature Engineering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Load Packages and Set Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“‚ Data source directory: ../DataSet/\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import warnings\n",
                "\n",
                "# Ignore warnings from pandas\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# --- ðŸ“‚ Step 1: Set File Paths ---\n",
                "data_dir = \"../DataSet/\"\n",
                "output_dir = \"./\"\n",
                "\n",
                "# Ensure output directory exists\n",
                "if not os.path.exists(output_dir):\n",
                "    os.makedirs(output_dir)\n",
                "\n",
                "print(f\"ðŸ“‚ Data source directory: {data_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Read Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "â³ Reading data...\n",
                        "âœ… Data reading complete!\n",
                        "   - Transaction records: 4435890 rows\n",
                        "   - Alert accounts: 1004 rows\n",
                        "   - Accounts to be predicted: 4780 rows\n"
                    ]
                }
            ],
            "source": [
                "if not df_txn.empty:\n",
                "    print(\"âš™ï¸ Starting T1 feature engineering...\\n\")\n",
                "\n",
                "    # Get all unique accounts\n",
                "    all_accts = pd.concat([df_txn['from_acct'], df_txn['to_acct']]).unique()\n",
                "    df_t1_features = pd.DataFrame({'acct': all_accts})\n",
                "\n",
                "    # T1.1: Number of unique destination accounts transferred to\n",
                "    print(\"   - Calculating number of unique destination accounts...\\n\")\n",
                "    df_num_to = df_txn.groupby('from_acct')['to_acct'].nunique().reset_index()\n",
                "    df_num_to.columns = ['acct', 'num_unique_dest_accts']\n",
                "    df_t1_features = pd.merge(df_t1_features, df_num_to, on='acct', how='left')\n",
                "\n",
                "    # T1.2: Number of unique source accounts received from\n",
                "    print(\"   - Calculating number of unique source accounts...\\n\")\n",
                "    df_num_from = df_txn.groupby('to_acct')['from_acct'].nunique().reset_index()\n",
                "    df_num_from.columns = ['acct', 'num_unique_source_accts']\n",
                "    df_t1_features = pd.merge(df_t1_features, df_num_from, on='acct', how='left')\n",
                "\n",
                "    # T1.3: High frequency transactions\n",
                "    print(\"   - Identifying high-frequency transaction accounts...\\n\")\n",
                "    df_from_counts = df_txn.groupby('from_acct').size().reset_index(name='send_count')\n",
                "    df_to_counts = df_txn.groupby('to_acct').size().reset_index(name='recv_count')\n",
                "    df_counts = pd.merge(df_from_counts, df_to_counts, left_on='from_acct', right_on='to_acct', how='outer').fillna(0)\n",
                "    df_counts['acct'] = df_counts['from_acct'].where(df_counts['from_acct'].notna(), df_counts['to_acct'])\n",
                "    df_counts['total_txns'] = df_counts['send_count'] + df_counts['recv_count']\n",
                "    high_freq_threshold = df_counts['total_txns'].quantile(0.95)\n",
                "    print(f\"   - High frequency threshold (95th percentile): {high_freq_threshold}\\n\")\n",
                "    df_counts['is_high_freq'] = (df_counts['total_txns'] > high_freq_threshold).astype(int)\n",
                "    df_t1_features = pd.merge(df_t1_features, df_counts[['acct', 'is_high_freq']], on='acct', how='left')\n",
                "\n",
                "    # T1.4: æ˜¯å¦æœ‰å¤–å¹£ (has_foreign_currency)\n",
                "    # æ ¹æ“šä½¿ç”¨è€…æä¾›çš„è³‡è¨Šï¼Œè³‡æ–™è¡¨èªªæ˜Žä¸­æåŠ currency_type ä»£è¡¨å¹£åˆ¥ï¼Œåˆ¤æ–·æ˜¯å¦ç‚º TWD å³å¯ã€‚\n",
                "    print(\"   - Identifying accounts with foreign currency transactions based on 'currency_type'...\\n\")\n",
                "    \n",
                "    # Assuming 'currency_type' column exists in df_txn based on user's input\n",
                "    # Check if 'currency_type' column actually exists before using it\n",
                "    if 'currency_type' in df_txn.columns:\n",
                "        df_txn['is_foreign_currency_txn'] = (df_txn['currency_type'] != 'TWD').astype(int)\n",
                "\n",
                "        # An account has foreign currency if any of its transactions involve foreign currency\n",
                "        # Check for 'from_acct'\n",
                "        foreign_from_accts = df_txn.groupby('from_acct')['is_foreign_currency_txn'].max().reset_index()\n",
                "        foreign_from_accts.columns = ['acct', 'has_foreign_currency_from']\n",
                "\n",
                "        # Check for 'to_acct'\n",
                "        foreign_to_accts = df_txn.groupby('to_acct')['is_foreign_currency_txn'].max().reset_index()\n",
                "        foreign_to_accts.columns = ['acct', 'has_foreign_currency_to']\n",
                "\n",
                "        # Merge and combine\n",
                "        df_foreign_currency = pd.merge(foreign_from_accts, foreign_to_accts, on='acct', how='outer')\n",
                "        df_foreign_currency['has_foreign_currency'] = (\n",
                "            df_foreign_currency['has_foreign_currency_from'].fillna(0) +\n",
                "            df_foreign_currency['has_foreign_currency_to'].fillna(0) > 0\n",
                "        ).astype(int)\n",
                "\n",
                "        df_t1_features = pd.merge(df_t1_features, df_foreign_currency[['acct', 'has_foreign_currency']], on='acct', how='left')\n",
                "    else:\n",
                "        print(\"   - Warning: 'currency_type' column not found in transaction data. 'has_foreign_currency' feature cannot be calculated accurately.\\n   - Defaulting 'has_foreign_currency' to 0 for all accounts.\")\n",
                "        df_t1_features['has_foreign_currency'] = 0\n",
                "\n",
                "    # Fill NaN values with 0\n",
                "    df_t1_features = df_t1_features.fillna(0)\n",
                "\n",
                "    print(\"âœ… T1 feature engineering complete!\\n\")\n",
                "    df_t1_features.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Feature Engineering (T1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš™ï¸ Starting T1 feature engineering...\n",
                        "   - Calculating number of unique destination accounts...\n",
                        "   - Calculating number of unique source accounts...\n",
                        "   - Identifying high-frequency transaction accounts...\n",
                        "   - High frequency threshold (95th percentile): 12.0\n",
                        "   - Identifying accounts with non-E.Sun transactions (proxy for foreign currency)...\n",
                        "âœ… T1 feature engineering complete!\n"
                    ]
                }
            ],
            "source": [
                "if not df_txn.empty:\n",
                "    print(\"âš™ï¸ Starting T1 feature engineering...\")\n",
                "\n",
                "    # Get all unique accounts\n",
                "    all_accts = pd.concat([df_txn['from_acct'], df_txn['to_acct']]).unique()\n",
                "    df_t1_features = pd.DataFrame({'acct': all_accts})\n",
                "\n",
                "    # T1.1: Number of unique destination accounts transferred to\n",
                "    print(\"   - Calculating number of unique destination accounts...\")\n",
                "    df_num_to = df_txn.groupby('from_acct')['to_acct'].nunique().reset_index()\n",
                "    df_num_to.columns = ['acct', 'num_unique_dest_accts']\n",
                "    df_t1_features = pd.merge(df_t1_features, df_num_to, on='acct', how='left')\n",
                "\n",
                "    # T1.2: Number of unique source accounts received from\n",
                "    print(\"   - Calculating number of unique source accounts...\")\n",
                "    df_num_from = df_txn.groupby('to_acct')['from_acct'].nunique().reset_index()\n",
                "    df_num_from.columns = ['acct', 'num_unique_source_accts']\n",
                "    df_t1_features = pd.merge(df_t1_features, df_num_from, on='acct', how='left')\n",
                "\n",
                "    # T1.3: High frequency transactions\n",
                "    print(\"   - Identifying high-frequency transaction accounts...\")\n",
                "    df_from_counts = df_txn.groupby('from_acct').size().reset_index(name='send_count')\n",
                "    df_to_counts = df_txn.groupby('to_acct').size().reset_index(name='recv_count')\n",
                "    df_counts = pd.merge(df_from_counts, df_to_counts, left_on='from_acct', right_on='to_acct', how='outer').fillna(0)\n",
                "    df_counts['acct'] = df_counts['from_acct'].where(df_counts['from_acct'] != 0, df_counts['to_acct'])\n",
                "    df_counts['total_txns'] = df_counts['send_count'] + df_counts['recv_count']\n",
                "    high_freq_threshold = df_counts['total_txns'].quantile(0.95)\n",
                "    print(f\"   - High frequency threshold (95th percentile): {high_freq_threshold}\")\n",
                "    df_counts['is_high_freq'] = (df_counts['total_txns'] > high_freq_threshold).astype(int)\n",
                "    df_t1_features = pd.merge(df_t1_features, df_counts[['acct', 'is_high_freq']], on='acct', how='left')\n",
                "\n",
                "    # T1.4: Foreign currency transactions (using non-E.Sun bank as a proxy)\n",
                "    print(\"   - Identifying accounts with non-E.Sun transactions (proxy for foreign currency)...\")\n",
                "    df_txn['has_non_esun_from'] = (df_txn['from_acct_type'] != '01').astype(int)\n",
                "    df_txn['has_non_esun_to'] = (df_txn['to_acct_type'] != '01').astype(int)\n",
                "    df_non_esun_from = df_txn.groupby('from_acct')['has_non_esun_from'].max().reset_index()\n",
                "    df_non_esun_to = df_txn.groupby('to_acct')['has_non_esun_to'].max().reset_index()\n",
                "    df_non_esun = pd.merge(df_non_esun_from, df_non_esun_to, left_on='from_acct', right_on='to_acct', how='outer')\n",
                "    df_non_esun['acct'] = df_non_esun['from_acct'].fillna(df_non_esun['to_acct'])\n",
                "    df_non_esun['has_foreign_currency'] = (df_non_esun['has_non_esun_from'].fillna(0) + df_non_esun['has_non_esun_to'].fillna(0) > 0).astype(int)\n",
                "    df_t1_features = pd.merge(df_t1_features, df_non_esun[['acct', 'has_foreign_currency']], on='acct', how='left')\n",
                "\n",
                "    # Fill NaN values with 0\n",
                "    df_t1_features = df_t1_features.fillna(0)\n",
                "\n",
                "    print(\"âœ… T1 feature engineering complete!\")\n",
                "    df_t1_features.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Create Train and Test Sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“¦ Splitting into train and test sets...\n",
                        "âœ… Splitting complete! Train: (1795326, 7), Test: (4780, 6)\n"
                    ]
                }
            ],
            "source": [
                "if 'df_t1_features' in locals():\n",
                "    print(\"ðŸ“¦ Splitting into train and test sets...\")\n",
                "\n",
                "    # Add labels to features\n",
                "    df_t1_features_labeled = pd.merge(df_t1_features, df_alert, on='acct', how='left')\n",
                "    df_t1_features_labeled['label'] = df_t1_features_labeled['acct'].isin(df_alert['acct']).astype(int)\n",
                "\n",
                "    predict_acct_set = set(df_predict['acct_id'])\n",
                "\n",
                "    # Test set\n",
                "    df_test_t1 = df_t1_features_labeled[df_t1_features_labeled['acct'].isin(predict_acct_set)].copy()\n",
                "    df_test_t1 = df_test_t1.drop(columns=['label'])\n",
                "\n",
                "    # Train set\n",
                "    df_train_t1 = df_t1_features_labeled[~df_t1_features_labeled['acct'].isin(predict_acct_set)].copy()\n",
                "\n",
                "    print(f\"âœ… Splitting complete! Train: {df_train_t1.shape}, Test: {df_test_t1.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Save Processed Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ’¾ Saving files...\n",
                        "   - Train features saved to: ./train_features_t1.csv\n",
                        "   - Test features saved to: ./test_features_t1.csv\n",
                        "ðŸŽ‰ All steps completed successfully!\n"
                    ]
                }
            ],
            "source": [
                "if 'df_train_t1' in locals() and 'df_test_t1' in locals():\n",
                "    print(\"ðŸ’¾ Saving files...\")\n",
                "    train_path = os.path.join(output_dir, 'train_features_t1.csv')\n",
                "    test_path = os.path.join(output_dir, 'test_features_t1.csv')\n",
                "\n",
                "    df_train_t1.to_csv(train_path, index=False)\n",
                "    df_test_t1.to_csv(test_path, index=False)\n",
                "\n",
                "    print(f\"   - Train features saved to: {train_path}\")\n",
                "    print(f\"   - Test features saved to: {test_path}\")\n",
                "    print(\"ðŸŽ‰ All steps completed successfully!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}